{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    " \n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    " \n",
    "# image transformations- defining how make image into a tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform##so the data is now a tensor\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "#where store reconstructed images \n",
    "def make_dir():\n",
    "    image_dir = 'FashionMNIST_Images'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "#saves reconstructed image \n",
    "def save_decoded_image(img, epoch):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, './FashionMNIST_Images/linear_ae_image{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (enc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (enc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (enc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (enc4): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (enc5): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (dec1): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (dec2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (dec3): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (dec4): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (dec5): Linear(in_features=256, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    " \n",
    "        # encoder- five layers\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=16)\n",
    " \n",
    "        # decoder- 5 layers\n",
    "        self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        x = F.relu(self.enc5(x))\n",
    " \n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x))\n",
    "        return x\n",
    " \n",
    "net = Autoencoder()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()#define loss function\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            # the _ would be an output lable but autoencoder soo\n",
    "            img, _ = data\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)#flatten image into 1D\n",
    "            #next four lines are taking an optimization step\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(img)\n",
    "            loss = criterion(outputs, img)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        loss = running_loss / len(trainloader)\n",
    "        train_loss.append(loss)\n",
    "        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch+1, NUM_EPOCHS, loss))\n",
    "        #saving image after every five epochs\n",
    "        if epoch % 5 == 0:\n",
    "            save_decoded_image(outputs.cpu().data, epoch)\n",
    "    # this is the loss after one epoch\n",
    "    return train_loss\n",
    " \n",
    "def test_image_reconstruction(net, testloader):\n",
    "     for batch in testloader:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        outputs = net(img)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        save_image(outputs, 'fashionmnist_reconstruction.png')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytochJN",
   "language": "python",
   "name": "pytochjn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
