{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Functions- show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(training_results):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(training_results['training_loss'], 'r')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('training loss iterations')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(training_results['validation_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()\n",
    "\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))\n",
    "    plt.show()\n",
    "\n",
    "def show_dataComp(data_sample,y):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(data_sample[1].numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title('y = ' + str(y))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_same_index(target, label):\n",
    "    label_indices = []\n",
    "\n",
    "    for i in range(len(target)):\n",
    "        if target[i] == label:\n",
    "            label_indices.append(i)\n",
    "\n",
    "    return label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparisonDataConsecutive(dataSet):\n",
    "    indices = []\n",
    "    #gets all the indices of the data obsv with same y from the dataset that is passed in\n",
    "    for i in range(5):\n",
    "        indlist = get_same_index(dataSet.targets, i)\n",
    "        indices.append(indlist)\n",
    "    subsets = []\n",
    "    [subsets.append(torch.utils.data.Subset(dataSet, i)) for i in indices]\n",
    "    comp = []\n",
    "    for indi in range(len(indices) - 1):\n",
    "        comp.append(int(min(len(subsets[indi]), len(subsets[indi + 1]))))\n",
    "    tot1 = sum(comp)\n",
    "    x = torch.zeros([tot1, 2, 28, 28], dtype=torch.float32)\n",
    "    y = torch.zeros([tot1,1])\n",
    "    # 1 for first pic greater, 0 for first pic less\n",
    "    k = 0\n",
    "    for i in range(len(subsets) - 1):\n",
    "        for j in range(int(comp[i] / 2)):\n",
    "            x[k][0] = subsets[i][j][0]\n",
    "            x[k][1] = subsets[i + 1][j][0]\n",
    "            y[k][0] = 0\n",
    "            k += 1\n",
    "        for j in range(int(comp[i] / 2), comp[i]):\n",
    "            x[k][1] = subsets[i][j][0]\n",
    "            x[k][0] = subsets[i + 1][j][0]\n",
    "            y[k][0] = 1\n",
    "            k += 1\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparisonDataNonconsecutive(dataSet):\n",
    "    indices = []\n",
    "    # gets all the indices of the data obsv with same y from the dataset that is passed in\n",
    "    for i in range(5):\n",
    "        indlist = get_same_index(dataSet.targets, i)\n",
    "        indices.append(indlist)\n",
    "    subsets = []\n",
    "    [subsets.append(torch.utils.data.Subset(dataSet, i)) for i in indices]\n",
    "    comp = {}\n",
    "    for i in range(len(subsets) - 2):\n",
    "        for j in range(i + 2, len(subsets), 1):\n",
    "            comp[(i, j)] = int(min(len(subsets[i]), len(subsets[j])))\n",
    "    tot = sum(comp.values())\n",
    "    x = torch.zeros([tot, 2, 28, 28], dtype=torch.float32)\n",
    "    y = torch.zeros([tot, 1])\n",
    "    k = 0\n",
    "    for key, values in comp.items():\n",
    "        for value in range(int(values / 2)):\n",
    "            x[k][0] = subsets[key[0]][value][0]\n",
    "            x[k][1] = subsets[key[1]][value][0]\n",
    "            y[k][0] = 0\n",
    "            k += 1\n",
    "        for value in range(int(values / 2), values):\n",
    "            x[k][0] = subsets[key[1]][value][0]\n",
    "            x[k][1] = subsets[key[0]][value][0]\n",
    "            y[k][0] = 1\n",
    "            k += 1\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainsetcomp(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.len = (x.shape[0])\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),])\n",
    "\n",
    "trainset = dsets.MNIST(root='./../data',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=transform)\n",
    "valset = dsets.MNIST(root='./../data',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = comparisonDataConsecutive(trainset)\n",
    "traindataComp = Trainsetcomp(x,y)\n",
    "x,y = comparisonDataConsecutive(valset)\n",
    "valdataComp = Trainsetcomp(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traindataComp,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valdataComp,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)\n",
    "x,y = comparisonDataNonconsecutive(valset)\n",
    "testdata = Trainsetcomp(x,y)\n",
    "testloader = torch.utils.data.DataLoader(testdata,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2 * 28 * 28\n",
    "hiddendim = [256,128,64]\n",
    "outd = 1\n",
    "# 0 if first image is less than and 1 if frist image is greater than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFull(nn.Module):\n",
    "    def __init__(self, ind,h1d,h2d,h3d,outd):\n",
    "        super(ModelFull, self).__init__()\n",
    "        self.lin1 = nn.Linear(ind, h1d)\n",
    "        self.lin2 = nn.Linear(h1d, h2d)\n",
    "        self.lin3 = nn.Linear(h2d, h3d)\n",
    "        self.lin4 = nn.Linear(h3d, outd)\n",
    "        self.activations = {'h1':[],'h2':[],'h3':[]}\n",
    "\n",
    "    def forward(self, x, recActivations = False):\n",
    "        if recActivations:\n",
    "            x1 = torch.relu(self.lin1(x))\n",
    "            self.activations['h1'].append(x1)\n",
    "            x2 = torch.relu(self.lin2(x1))\n",
    "            self.activations['h2'].append(x2)\n",
    "            x3 = torch.relu(self.lin3(x2))\n",
    "            self.activations['h3'].append(x3)\n",
    "            x4 = torch.sigmoid(self.lin4(x3))\n",
    "            return x4\n",
    "        else:\n",
    "            x1 = torch.relu(self.lin1(x))\n",
    "            x2 = torch.relu(self.lin2(x1))\n",
    "            x3 = torch.relu(self.lin3(x2))\n",
    "            x4 = torch.sigmoid(self.lin4(x3))\n",
    "            return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs = 30):\n",
    "    lossList = []\n",
    "    #time0 = time()\n",
    "    for i in range(epochs):\n",
    "        runningLoss = 0\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x.view(-1, 2 * 28 *28))\n",
    "            #print(yhat.shape)\n",
    "            #print(y.shape)\n",
    "            loss = criterion(yhat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            runningLoss += loss.item()\n",
    "        print('epoch ', i, ' loss: ', str(runningLoss / len(traindataComp)))\n",
    "        lossList.append(runningLoss / len(traindataComp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelFull(ind,hiddendim[0],hiddendim[1],hiddendim[2], outd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  loss:  0.008575960630377544\n",
      "epoch  1  loss:  0.003752651454524602\n",
      "epoch  2  loss:  0.002658630019780359\n",
      "epoch  3  loss:  0.0015895875997655416\n",
      "epoch  4  loss:  0.0012948909899556458\n",
      "epoch  5  loss:  0.001110205670841418\n",
      "epoch  6  loss:  0.0015078286783617371\n",
      "epoch  7  loss:  0.0009902292535938935\n",
      "epoch  8  loss:  0.0008478872185409142\n",
      "epoch  9  loss:  0.0007440199225985267\n",
      "epoch  10  loss:  0.0006870708614965823\n",
      "epoch  11  loss:  0.0006146428428192812\n",
      "epoch  12  loss:  0.0005412911956966704\n",
      "epoch  13  loss:  0.0005852784405366366\n",
      "epoch  14  loss:  0.0004439410185467331\n",
      "epoch  15  loss:  0.00036050798534829095\n",
      "epoch  16  loss:  0.0003289471525574093\n",
      "epoch  17  loss:  0.0002800824272379851\n",
      "epoch  18  loss:  0.00025627378670592307\n",
      "epoch  19  loss:  0.00019368897315860068\n",
      "epoch  20  loss:  0.00020857671430596873\n",
      "epoch  21  loss:  0.0001176749896105278\n",
      "epoch  22  loss:  0.0005636333829042921\n",
      "epoch  23  loss:  0.0005239267853290685\n",
      "epoch  24  loss:  0.0002438008596358646\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.03)\n",
    "results = train(model,criterion,optimizer,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3858\n",
      "4004\n",
      "valset accuracy:  0.9635364635364635\n"
     ]
    }
   ],
   "source": [
    "## Consecutive test set\n",
    "totcount = 0\n",
    "correctcount = 0\n",
    "for x,y in valloader:\n",
    "    x = x.view(-1, 2 * 28 *28)\n",
    "    with torch.no_grad():\n",
    "        yhat = model(x)\n",
    "    ones = torch.ones(yhat.shape)\n",
    "    yhat = torch.where(yhat>.9, ones, yhat)\n",
    "    z = torch.zeros(yhat.shape)\n",
    "    yhat = torch.where(yhat<0.1, z, yhat)\n",
    "    for i,j in zip(yhat,y):\n",
    "        if i[0] == j[0]:\n",
    "            correctcount+=1\n",
    "        totcount+=1\n",
    "print(correctcount)\n",
    "print(totcount)\n",
    "#print(len(dataPairing.valdataComp))\n",
    "print('valset accuracy: ', correctcount/totcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9167\n",
      "9918\n",
      "test set accuracy:  0.9242790885259125\n"
     ]
    }
   ],
   "source": [
    "## non consecutive test set\n",
    "for x,y in testloader:\n",
    "    x = x.view(-1, 2 * 28 *28)\n",
    "    with torch.no_grad():\n",
    "        yhat = model(x)\n",
    "    ones = torch.ones(yhat.shape)\n",
    "    yhat = torch.where(yhat>.5, ones, yhat)\n",
    "    z = torch.zeros(yhat.shape)\n",
    "    yhat = torch.where(yhat<0.5, z, yhat)\n",
    "    wrongC = 0\n",
    "    for i in range(len(y)):\n",
    "        #print(i)\n",
    "        if yhat[i][0] == y[i][0]:\n",
    "            correctcount+=1\n",
    "            #p = torch.reshape(x[i], (2,28,28))\n",
    "            #show_dataComp(p, y[i])\n",
    "            \n",
    "        else:\n",
    "            #if wrongC < 2:\n",
    "                #p = torch.reshape(x[i], (2,28,28))\n",
    "                #show_dataComp(p, yhat[i])\n",
    "            wrongC += 1\n",
    "        totcount+=1\n",
    "print(correctcount)\n",
    "print(totcount)\n",
    "print('test set accuracy: ', correctcount/totcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look activations of the numbers of equal step\n",
    "<br>\n",
    "hyp: activations of the comparison pairs should be more similar if the the difference in the comparison is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = traindataComp[0][0].view(-1, 2 * 28 *28)\n",
    "yhat = model.forward(x,recActivations=True)\n",
    "yhat[0].round() == traindataComp[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.activations['h1'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytochJN",
   "language": "python",
   "name": "pytochjn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
